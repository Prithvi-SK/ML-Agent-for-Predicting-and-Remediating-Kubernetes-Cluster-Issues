{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1742649189664,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "EGwGgpjp7Tt_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "packages = [\"pandas\", \"numpy\", \"matplotlib\", \"scikit-learn\", \"tensorflow\"]\n",
    "\n",
    "for package in packages:\n",
    "    install_if_missing(package)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "file_path_2 = \"../data/guidewire-2.csv\"\n",
    "df = pd.read_csv(file_path_2)\n",
    "\n",
    "# Convert Timestamp to datetime\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "df = df.sort_values(by=\"Timestamp\")\n",
    "\n",
    "# Compute total network packets dropped\n",
    "df[\"Network Packets Dropped (p/s)\"] = df[\"Network Transmit Packets Dropped (p/s)\"] + df[\"Network Receive Packets Dropped (p/s)\"]\n",
    "\n",
    "\n",
    "# Select network-related features\n",
    "network_features = [\"Network Receive Bytes\", \"Network Transmit Bytes\",\n",
    "                    \"Network Receive Packets (p/s)\", \"Network Transmit Packets (p/s)\",\n",
    "                    \"Network Packets Dropped (p/s)\"]\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "df[network_features] = scaler.fit_transform(df[network_features])\n",
    "\n",
    "# Generate anomaly labels (1 = network failure, 0 = normal)\n",
    "df[\"Network Failure\"] = (df[\"Network Packets Dropped (p/s)\"] > 0.05).astype(int)\n",
    "\n",
    "# Convert to NumPy array\n",
    "data = df[network_features].values\n",
    "labels = df[\"Network Failure\"].values\n",
    "\n",
    "# Create sequences for LSTM (past 10 steps)\n",
    "def create_sequences(data, labels, seq_length=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 10\n",
    "X, y = create_sequences(data, labels, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396388,
     "status": "ok",
     "timestamp": 1742649609311,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "DF80iG928XZm",
    "outputId": "83b580d2-c662-4a0a-89ac-e5a27d135502"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:50:38.995283: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-03-23 20:50:38.995360: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-03-23 20:50:38.995375: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742743238.995453 3106048 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1742743238.995545 3106048 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:50:40.107415: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.4675 - val_accuracy: 0.9523 - val_loss: 0.2356\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8040 - loss: 0.4535 - val_accuracy: 0.9523 - val_loss: 0.2353\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8039 - loss: 0.4497 - val_accuracy: 0.9523 - val_loss: 0.2109\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8038 - loss: 0.4479 - val_accuracy: 0.9520 - val_loss: 0.2276\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8071 - loss: 0.4447 - val_accuracy: 0.9523 - val_loss: 0.2065\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8049 - loss: 0.4449 - val_accuracy: 0.9522 - val_loss: 0.2037\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8030 - loss: 0.4452 - val_accuracy: 0.9522 - val_loss: 0.2127\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8074 - loss: 0.4416 - val_accuracy: 0.9523 - val_loss: 0.2107\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8060 - loss: 0.4421 - val_accuracy: 0.9523 - val_loss: 0.2166\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.8052 - loss: 0.4418 - val_accuracy: 0.9520 - val_loss: 0.2308\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(seq_length, X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train Model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get LSTM Predictions\n",
    "lstm_preds = lstm_model.predict(X_test).flatten()\n",
    "lstm_preds = (lstm_preds > 0.5).astype(int)  # Convert probabilities to binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392475,
     "status": "ok",
     "timestamp": 1742650123203,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "_6LeTMrB_L6i",
    "outputId": "be107e2f-be71-4362-cdaf-57a903ded91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 0.0194 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 9.2431e-04 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 4.9294e-04 - val_loss: 7.8140e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 2.6284e-04 - val_loss: 3.8512e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 1.1548e-04 - val_loss: 2.2461e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 8.7575e-05 - val_loss: 2.0376e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 7.5694e-05 - val_loss: 2.6696e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 6.7049e-05 - val_loss: 1.2974e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - loss: 6.0417e-05 - val_loss: 1.1345e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 5.1957e-05 - val_loss: 1.5177e-04\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder Model\n",
    "input_dim = X_train.shape[2]\n",
    "autoencoder_input = Input(shape=(seq_length, input_dim))\n",
    "\n",
    "# Encoder\n",
    "encoded = LSTM(64, return_sequences=True)(autoencoder_input)\n",
    "encoded = LSTM(32, return_sequences=False)(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(64, activation=\"relu\")(encoded)\n",
    "decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
    "\n",
    "# Autoencoder Model\n",
    "autoencoder = Model(autoencoder_input, decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train Autoencoder\n",
    "autoencoder.fit(X_train, X_train[:, -1, :], epochs=10, batch_size=32, validation_data=(X_test, X_test[:, -1, :]))\n",
    "\n",
    "# Compute reconstruction errors\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "reconstruction_errors = np.mean(np.abs(reconstructions - X_test[:, -1, :]), axis=1)\n",
    "\n",
    "# Threshold for anomaly detection\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "anomaly_preds = (reconstruction_errors > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1742650603327,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "9vjfbDpDBKT_",
    "outputId": "2f97c10e-cc9a-4149-ecbf-76b19c3b23e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.951995199519952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       954\n",
      "           1       0.95      1.00      0.98     19044\n",
      "\n",
      "    accuracy                           0.95     19998\n",
      "   macro avg       0.48      0.50      0.49     19998\n",
      "weighted avg       0.91      0.95      0.93     19998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid model decision: if either LSTM or Autoencoder detects an anomaly, classify as failure\n",
    "final_preds = np.logical_or(lstm_preds, anomaly_preds).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, final_preds))\n",
    "print(classification_report(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxLmkXQEEfWg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMAmy4g52QqEghZE/j4M2BJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
