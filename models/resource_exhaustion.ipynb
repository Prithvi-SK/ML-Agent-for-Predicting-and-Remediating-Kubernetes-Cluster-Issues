{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5271,
     "status": "ok",
     "timestamp": 1742486130957,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "7Iql6vjxQhY3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "file_path_2 = \"../data/guidewire-2.csv\"\n",
    "df = pd.read_csv(file_path_2)\n",
    "\n",
    "# Convert Timestamp to datetime\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "df = df.sort_values(by=\"Timestamp\")\n",
    "\n",
    "# Select relevant features\n",
    "features = [\"CPU Usage (%)\", \"Memory Usage (%)\", \"Memory Requests (%)\",\n",
    "            \"FS Reads Total (MB)\", \"FS Writes Total (MB)\"]\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# Generate binary labels (1 = resource exhaustion, 0 = normal)\n",
    "df[\"Resource Exhaustion\"] = ((df[\"CPU Usage (%)\"] > 0.9) | (df[\"Memory Usage (%)\"] > 0.9)).astype(int)\n",
    "\n",
    "# Convert to NumPy array\n",
    "data = df[features].values\n",
    "labels = df[\"Resource Exhaustion\"].values\n",
    "\n",
    "# Create sequences for LSTM (past 10 steps)\n",
    "def create_sequences(data, labels, seq_length=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 10\n",
    "X, y = create_sequences(data, labels, seq_length)\n",
    "\n",
    "# Split into train and test sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38290,
     "status": "ok",
     "timestamp": 1742486183596,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "4Zw7u5JURDnM",
    "outputId": "89ad2b60-181a-4b98-fecc-021653c5b557"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 21:13:23.140581: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-03-23 21:13:23.140608: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-03-23 21:13:23.140616: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742744603.140626 3143114 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1742744603.140644 3143114 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 21:13:24.284228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - accuracy: 0.9843 - loss: 0.0757 - val_accuracy: 0.9547 - val_loss: 0.2185\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0464 - val_accuracy: 0.9547 - val_loss: 0.2004\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0460 - val_accuracy: 0.9547 - val_loss: 0.1934\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0432 - val_accuracy: 0.9547 - val_loss: 0.1928\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0441 - val_accuracy: 0.9547 - val_loss: 0.2056\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9924 - loss: 0.0421 - val_accuracy: 0.9547 - val_loss: 0.1981\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0426 - val_accuracy: 0.9547 - val_loss: 0.2082\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0418 - val_accuracy: 0.9547 - val_loss: 0.2128\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0407 - val_accuracy: 0.9547 - val_loss: 0.2045\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0432 - val_accuracy: 0.9547 - val_loss: 0.2118\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(seq_length, X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train Model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get LSTM Predictions\n",
    "lstm_preds = lstm_model.predict(X_test).flatten()\n",
    "lstm_preds = (lstm_preds > 0.5).astype(int)  # Convert probabilities to binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1742486196576,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "uhrlbFYHRIT_"
   },
   "outputs": [],
   "source": [
    "# Flatten LSTM outputs for XGBoost\n",
    "X_train_xgb = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_xgb = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "xgb_model.fit(X_train_xgb, y_train)\n",
    "\n",
    "# Get XGBoost Predictions\n",
    "xgb_preds = xgb_model.predict(X_test_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1742486213726,
     "user": {
      "displayName": "Prithvi SK",
      "userId": "12460935042064814316"
     },
     "user_tz": -330
    },
    "id": "5xNpKn0DRUnE",
    "outputId": "3cc8ec1e-3d51-4d30-9d87-714d66dfd3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9546954695469547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     19092\n",
      "           1       0.00      0.00      0.00       906\n",
      "\n",
      "    accuracy                           0.95     19998\n",
      "   macro avg       0.48      0.50      0.49     19998\n",
      "weighted avg       0.91      0.95      0.93     19998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cc/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Hybrid model decision: if either LSTM or XGBoost predicts exhaustion, classify as exhaustion\n",
    "final_preds = np.logical_or(lstm_preds, xgb_preds).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, final_preds))\n",
    "print(classification_report(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIH-vHUoRY1h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyONiISuhCYGJGCuGgPmkec9",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
